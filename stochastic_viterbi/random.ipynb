{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54ecc198",
   "metadata": {},
   "source": [
    "#  Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774d8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy 0.063 {'Healthy': 0.063, 'Fever': 0.036} ['Healthy', 'Healthy']\n",
      "Fever 0.01512 {'Healthy': 0.00441, 'Fever': 0.01512} ['Healthy', 'Healthy', 'Fever']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Healthy', 'Healthy', 'Fever'], -11.772868005544115)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "def format_prob(state, transition, transition_states, emission, emission_states):\n",
    "    # input prob as list of lists and states as list of states\n",
    "    # output: pandas dataframe with states as indices\n",
    "    df_state = pd.DataFrame(state, columns = transition_states)\n",
    "    df_trans = pd.DataFrame(transition, index = transition_states, columns = transition_states)\n",
    "    df_em = pd.DataFrame(emission, index = transition_states, columns = emission_states,)\n",
    "    return df_state, df_trans, df_em\n",
    "\n",
    "def viterbi(state, transition, transition_states, emission, emission_states, seq):\n",
    "    # input: list of state, transition, and emission prob as lists\n",
    "    # state should be in format: [[p1, p2, ...]]\n",
    "    # transition indices: list of states\n",
    "    state, transition, emission = format_prob(state, transition, transition_states, emission, emission_states)\n",
    "    \n",
    "    if transition.shape[1]!= emission.shape[0]: \n",
    "        # num rows of trans. states must equal num col. of emission states\n",
    "        print(\"Number of rows in transition state must equal number of columns in emission states\", file=sys.stderr)\n",
    "\n",
    "    path = []\n",
    "    seq = [*seq]\n",
    "    for s,i in zip(seq, range(len(seq))):\n",
    "        if i == 0: # if first in seq, use state prob.\n",
    "            prob1 = {}\n",
    "            for st in state:\n",
    "                prob1[st] = float(state[st] * emission[s][st]) \n",
    "            t_state = max(prob1, key=prob1.get)\n",
    "            path.append(t_state) # add max probability to path\n",
    "            prev_prob = prob1[path[0]]\n",
    "            v_prob = math.log2(prev_prob)\n",
    "            prev_state = t_state\n",
    "        else:\n",
    "            prob = {}           \n",
    "            for t in transition:                    \n",
    "                prob[t] = prev_prob * transition[prev_state][t] * emission[s][t]\n",
    "            x = max(prob, key=prob.get)\n",
    "            path.append(x)\n",
    "            prev_prob = prob[x]\n",
    "            print(x, prev_prob, prob, path)\n",
    "            prev_state = x\n",
    "            v_prob += math.log2(prev_prob)\n",
    "    return path, v_prob\n",
    "    \n",
    "answer = \" HHHLLLLLL\"\n",
    "emission_states = [\"normal\", \"cold\", \"dizzy\"]\n",
    "transition_states = [\"Healthy\", \"Fever\"]\n",
    "state = [[0.6, 0.4]]\n",
    "transition = [[0.7,0.3], [0.4,0.6]] \n",
    "emission = [[0.5,0.3,0.1], [0.1,0.3,0.6]]\n",
    "seq = [\"normal\", \"cold\", \"dizzy\"]\n",
    "viterbi(state, transition, transition_states, emission, emission_states, seq)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbba273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     H    L\n",
       " 0  0.5  0.5,\n",
       "      H    L\n",
       " H  0.5  0.4\n",
       " L  0.4  0.6,\n",
       "      A    C    G    T\n",
       " H  0.2  0.3  0.3  0.2\n",
       " L  0.3  0.2  0.2  0.3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = [[0.5, 0.5]]\n",
    "transition = [[0.5,0.4], [0.4,0.6]] \n",
    "transition_states = ['H', 'L']\n",
    "emission = [[0.2,0.3,0.3,0.2], [0.3,0.2,0.2,0.3]] # hidden states, row: A,C,G,T, col: H, L\n",
    "emission_states = ['A', 'C', 'G', 'T']\n",
    "\n",
    "seq = 'GGCACTGAA'\n",
    "format_prob(state, transition, transition_states, emission, emission_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8cdc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'H', 'H', 'L', 'H', 'L', 'H', 'L', 'L']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with log\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "state = [[0.5, 0.5]]\n",
    "transition = [[0.5,0.4], [0.4,0.6]] \n",
    "transition_states = ['H', 'L']\n",
    "emission = [[0.2,0.3,0.3,0.2], [0.3,0.2,0.2,0.3]] # hidden states, row: A,C,G,T, col: H, L\n",
    "emission_states = ['A', 'C', 'G', 'T']\n",
    "\n",
    "seq = 'GGCACTGAA'\n",
    "seq = [*seq]\n",
    "\n",
    "def format_prob(state, transition, transition_states, emission, emission_states):\n",
    "    # input prob as list of lists and states as list of states\n",
    "    # output: pandas dataframe with states as indices\n",
    "    df_state = pd.DataFrame(state, columns = transition_states)\n",
    "    df_trans = pd.DataFrame(transition, index = transition_states, columns = transition_states)\n",
    "    df_em = pd.DataFrame(emission, index = transition_states, columns = emission_states,)\n",
    "    return df_state, df_trans, df_em\n",
    "\n",
    "def viterbi(state, transition, transition_states, emission, emission_states, seq):\n",
    "    # input: list of state, transition, and emission prob as lists\n",
    "    # state should be in format: [[p1, p2, ...]]\n",
    "    # transition indices: list of states\n",
    "    state, transition, emission = format_prob(state, transition, transition_states, emission, emission_states)\n",
    "    \n",
    "    if transition.shape[1]!= emission.shape[0]: \n",
    "        # num rows of trans. states must equal num col. of emission states\n",
    "        print(\"Number of rows in transition state must equal number of columns in emission states\", file=sys.stderr)\n",
    "\n",
    "    path = []\n",
    "    for s,i in zip(seq, range(len(seq))):\n",
    "        if i == 0: # if first in seq, use state prob.\n",
    "            prob1 = {}\n",
    "            for st in state:\n",
    "                prob1[st] = float(state[st] * emission[s][st]) \n",
    "            t_state = max(prob1, key=prob1.get)\n",
    "            path.append(t_state) # add max probability to path\n",
    "            prev_prob = math.log2(prob1[path[0]])\n",
    "            prev_state = t_state\n",
    "        else:\n",
    "            prob = {}           \n",
    "            for t in transition:                    \n",
    "                prob[t] = prev_prob +  math.log2(transition[prev_state][t] * emission[s][t])\n",
    "            x = max(prob, key=prob.get)\n",
    "            path.append(x)\n",
    "            prev_prob = prob[x]\n",
    "            prev_state = x\n",
    "    return path\n",
    "\n",
    "viterbi(state, transition, transition_states, emission, emission_states, seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3c8e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Healthy', 'Healthy', 'Fever'], 0.01512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with log\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def format_prob(state, transition, transition_states, emission, emission_states):\n",
    "    # input prob as list of lists and states as list of states\n",
    "    # output: pandas dataframe with states as indices\n",
    "    df_state = pd.DataFrame(state, columns = transition_states)\n",
    "    df_trans = pd.DataFrame(transition, index = transition_states, columns = transition_states)\n",
    "    df_em = pd.DataFrame(emission, index = transition_states, columns = emission_states,)\n",
    "    return df_state, df_trans, df_em\n",
    "\n",
    "def viterbi(state, transition, transition_states, emission, emission_states, seq, log=0):\n",
    "    # input: list of state, transition, and emission prob as lists\n",
    "    # state should be in format: [[p1, p2, ...]]\n",
    "    # transition indices: list of states\n",
    "    state, transition, emission = format_prob(state, transition, transition_states, emission, emission_states)\n",
    "    \n",
    "    if transition.shape[1]!= emission.shape[0]: \n",
    "        # num rows of trans. states must equal num col. of emission states\n",
    "        print(\"Number of rows in transition state must equal number of columns in emission states\", file=sys.stderr)\n",
    "    probability = 1\n",
    "    path = []\n",
    "    if type(seq) == str:\n",
    "        seq = [*seq]\n",
    "    for s,i in zip(seq, range(len(seq))):\n",
    "        if i == 0: # if first in seq, use state prob.\n",
    "            prob1 = {}\n",
    "            for st in state:\n",
    "                prob1[st] = float(state[st] * emission[s][st]) \n",
    "            t_state = max(prob1, key=prob1.get)\n",
    "            path.append(t_state) # add max probability to path\n",
    "            if log == 1:\n",
    "                prev_prob = math.log2(prob1[path[0]])\n",
    "            else:\n",
    "                prev_prob = prob1[path[0]]\n",
    "            prev_state = t_state\n",
    "        else:\n",
    "            prob = {}           \n",
    "            for t in transition:      \n",
    "                if log == 1:\n",
    "                    prob[t] = prev_prob +  math.log2(transition[prev_state][t] * emission[s][t])\n",
    "                else:\n",
    "                    prob[t] = prev_prob * (transition[prev_state][t] * emission[s][t])\n",
    "            x = max(prob, key=prob.get)\n",
    "            path.append(x)\n",
    "            prev_prob = prob[x]\n",
    "            prev_state = x\n",
    "    return path, prev_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "answer\n",
    "$ python viterbi_example.py\n",
    "         0          1          2\n",
    "Healthy: 0.30000 0.08400 0.00588\n",
    "Fever: 0.04000 0.02700 0.01512\n",
    "The steps of states are Healthy Healthy Fever with highest probability of 0.01512\n",
    "\"\"\"\n",
    "\n",
    "emission_states = [\"normal\", \"cold\", \"dizzy\"]\n",
    "transition_states = [\"Healthy\", \"Fever\"]\n",
    "state = [[0.6, 0.4]]\n",
    "transition = [[0.7,0.3], [0.4,0.6]] \n",
    "emission = [[0.5,0.3,0.1], [0.1,0.3,0.6]]\n",
    "seq = [\"normal\", \"cold\", \"dizzy\"]\n",
    "viterbi(state, transition, transition_states, emission, emission_states, seq)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3180398",
   "metadata": {},
   "source": [
    "# pHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970f895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A' 'G' '-' '-' '-' 'C']\n",
      " ['A' '-' 'A' '-' '-' 'C']\n",
      " ['A' 'T' '-' 'G' 'A' '-']\n",
      " ['-' '-' 'A' 'A' 'A' 'C']\n",
      " ['A' 'G' '-' '-' '-' 'C']]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# profile Hidden Markov Model\n",
    "# 1. get transition and emission probabilities\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def parse_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        # read file into numpy array (rows: array of the sequence)\n",
    "        lines = f.readlines()\n",
    "        seq = [] \n",
    "        for line in lines:\n",
    "            if not line.startswith('>') and line != \"\": \n",
    "                seq.append(np.array(list(line.strip())))\n",
    "        seq = np.array(seq)\n",
    "    return seq\n",
    "\n",
    "def probabilities(seq):\n",
    "    # def all the match, insert, and delete states\n",
    "    # get transition and emission probabilities\n",
    "    states = ['M'] # this is the begin state (not in seq)\n",
    "    for i, col in enumerate(seq.T):\n",
    "        x = Counter(col)\n",
    "        if '-' in x:\n",
    "            gaps = x['-']\n",
    "        else:\n",
    "            gaps = 0\n",
    "        nuc = sum(x.values()) - gaps\n",
    "        if i == 0:\n",
    "            if nuc > gaps:        \n",
    "                states.append('M') # if there are more nucleotides than '-' then it's a match, else insertion (for the first col)\n",
    "            else:\n",
    "                states.append('I')\n",
    "        else:\n",
    "            if nuc > gaps:        \n",
    "                states.append('M')\n",
    "            elif states[i] == 'M': # if previous state was a match, and there are more gaps than nuc, next state is deletion (M->D)\n",
    "                states.append('D')\n",
    "            else:\n",
    "                # states[i+1] = ['I']\n",
    "                states.append('I')\n",
    "    return states\n",
    "    transition = {}\n",
    "    emission = {}\n",
    "\n",
    "seq = parse_file('sample.txt')\n",
    "prob = probabilities(seq)\n",
    "print(seq)\n",
    "print(len(seq[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9839dc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['M', 'M', 'M', 'I', 'I', 'I', 'M'],\n",
       " array([['M', 'M', '-', '-', '-', 'M'],\n",
       "        ['M', 'D', 'I', '-', '-', 'M'],\n",
       "        ['M', 'M', '-', 'I', 'I', 'D'],\n",
       "        ['D', 'D', 'I', 'I', 'I', 'M'],\n",
       "        ['M', 'M', '-', '-', '-', 'M']], dtype='<U1'),\n",
       " array([['A', 'G', '-', '-', '-', 'C'],\n",
       "        ['A', '-', 'A', '-', '-', 'C'],\n",
       "        ['A', 'T', '-', 'G', 'A', '-'],\n",
       "        ['-', '-', 'A', 'A', 'A', 'C'],\n",
       "        ['A', 'G', '-', '-', '-', 'C']], dtype='<U1'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_states(seq):\n",
    "    # marked: mark columns with match or mismatch\n",
    "    marked = [\"M\"]\n",
    "    for i, col in enumerate(seq.T):\n",
    "        x = Counter(col) \n",
    "        if '-' in x:\n",
    "            gaps = x['-']\n",
    "        else:\n",
    "            gaps = 0\n",
    "        nuc = sum(x.values()) - gaps\n",
    "        if nuc > gaps:       \n",
    "            marked.append('M')\n",
    "        else:\n",
    "            marked.append('I')\n",
    "\n",
    "    states = []\n",
    "    for row, mark in zip(seq.T, marked[1:]):\n",
    "        col_states = []\n",
    "        for col in row:\n",
    "            if col != \"-\" and mark == \"M\": # nuc in M state = M\n",
    "                col_states.append(\"M\")\n",
    "            elif col == \"-\" and mark == \"M\": # gap in M state = D\n",
    "                col_states.append(\"D\")\n",
    "            elif col != \"-\" and mark == \"I\": # nuc in I state = I\n",
    "                col_states.append(\"I\")\n",
    "            else:                            # ignore gaps in I state\n",
    "                col_states.append(\"-\") \n",
    "        states.append(np.array(col_states)) # problem is that states is appending by col.  need to flip .T\n",
    "    states = np.array(states).T\n",
    "    \n",
    "    \n",
    "    return marked, states,\n",
    "marked, states = get_states(seq)\n",
    "marked, states, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf71861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['M', 'M', '-', '-', '-', 'M'],\n",
       "       ['M', 'D', 'I', '-', '-', 'M'],\n",
       "       ['M', 'M', '-', 'I', 'I', 'D'],\n",
       "       ['D', 'D', 'I', 'I', 'I', 'M'],\n",
       "       ['M', 'M', '-', '-', '-', 'M']], dtype='<U1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([['M', 'M', '-', '-', '-', 'M'],\n",
    "        ['M', 'D', 'I', '-', '-', 'M'],\n",
    "        ['M', 'M', '-', 'I', 'I', 'D'],\n",
    "        ['D', 'D', 'I', 'I', 'I', 'M'],\n",
    "        ['M', 'M', '-', '-', '-', 'M']])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71121804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: {'MM': 0.8, 'MD': 0.5555555555555556}, \n",
      " transition_counts: [{'MM': 4, 'MD': 1}, {'MM': 3, 'MD': 1, 'DD': 1}, {'MM': 2, 'IM': 2, 'MI': 1, 'ID': 1, 'II': 3, 'DI': 2}, {'MM': 4, 'DM': 1}], \n",
      " prob_t: [{'MM': 0.8, 'MD': 0.2}, {'MM': 0.6, 'MD': 0.2, 'DD': 0.2}, {'MM': 0.18181818181818182, 'IM': 0.18181818181818182, 'MI': 0.09090909090909091, 'ID': 0.09090909090909091, 'II': 0.2727272727272727, 'DI': 0.18181818181818182}, {'MM': 0.8, 'DM': 0.2}]\n"
     ]
    }
   ],
   "source": [
    "def transition(states, seq, marked):\n",
    "    transition_counts = [] # length = # of match states\n",
    "    #freq_t = {ind: {} for ind, key in enumerate(marked)}\n",
    "    freq_t = {}\n",
    "    matches = 0\n",
    "    match_states = [ind for ind, ele in enumerate(marked) if ele == \"M\"] # gets indices of match states\n",
    "    match_states[-1] = match_states[-1]-1 # b/c length is +1 of seq, so last index will be out of index\n",
    "    state_prob = {}\n",
    "    for ind, m in enumerate(match_states[:-1]):\n",
    "        match_before = match_states[m] # index col of match state before insert states\n",
    "        match_after = match_states[m+1] \n",
    "        # state probability: M->state in first column\n",
    "        if m == match_states[0]:\n",
    "            for row in states.T[0]:\n",
    "                entry = (\"M{}\".format(row))\n",
    "                state_prob[entry] = state_prob.get(entry, 0) + 1\n",
    "        # insert state(s)\n",
    "        elif match_states[m]+1 != match_states[m+1]: \n",
    "            insert_nuc = seq.T[m:match_states[m+1]] # gets all the seq col. that are in the insert state\n",
    "            insert_nuc = insert_nuc != \"-\" # bool array of all the nuc\n",
    "            for ind_r, row_i in enumerate(insert_nuc.T): \n",
    "                if np.any(row_i != False): # contains nuc. in insert col\n",
    "                    if  states[ind_r][match_before-1] == \"M\":\n",
    "                        freq_t[\"MI\"] = freq_t.get(\"MI\", 0) + 1\n",
    "                    if states[ind_r][match_after] == \"M\": # I->M\n",
    "                        freq_t[\"IM\"] = freq_t.get(\"IM\", 0) + 1\n",
    "                    elif states[ind_r][match_after] == \"D\": # I->D\n",
    "                        freq_t[\"ID\"] = freq_t.get(\"ID\", 0) + 1 \n",
    "                    # I->I\n",
    "                    for ind_c, col_c in enumerate(row_i[1:]):\n",
    "                        if row_i[ind_c-1] == True and col_c == True:\n",
    "                            freq_t[\"II\"] = freq_t.get(\"II\", 0) + 1 \n",
    "                else:\n",
    "                    if states[ind_r][match_before-1] == \"M\" and states[ind_r][match_after] == \"M\":\n",
    "                        freq_t[\"MM\"] = freq_t.get(\"MM\", 0) + 1                     \n",
    "\n",
    "         # match state\n",
    "        for j, row in enumerate(states.T[m]): # Iterate down col at corresponding index to match state in marked\n",
    "            if m == 0: # if the first col, assume the previous state was a match (the begin state)\n",
    "                entry = (\"M{}\".format(row))\n",
    "                freq_t[entry] = freq_t.get(entry, 0) + 1\n",
    "            else:\n",
    "                if states.T[m-1][j] == \"-\" or row == \"-\": # ignore gaps in insert state\n",
    "                    continue\n",
    "                entry = (\"{}{}\".format(states.T[m-1][j],row))\n",
    "                freq_t[entry] = freq_t.get(entry, 0) + 1\n",
    "        transition_counts.append(freq_t)\n",
    "        freq_t = {}\n",
    "    # if last column, assume transition is to match state?\n",
    "    for j, row in enumerate(states.T[-1]):\n",
    "        entry = (\"{}{}\".format(row,\"M\"))\n",
    "        freq_t[entry] = freq_t.get(entry, 0) + 1\n",
    "    transition_counts.append(freq_t)\n",
    "    freq_t = {}\n",
    "    # get probability of each starting state\n",
    "    for key, value in state_prob.items():\n",
    "        \n",
    "        state_prob[key] = value/sum(state_prob.values())\n",
    "    \"\"\"\n",
    "    # consolidate counts\n",
    "    trans_counts = {}\n",
    "    for i in transition_counts:\n",
    "        for key, value in i.items():\n",
    "            trans_counts[key] = trans_counts.get(key, 0) + value\n",
    "    # get totals of all the transitions from a state (M,D,I)\n",
    "    totals_t = {\"M\":0, \"D\":0, \"I\":0}\n",
    "    for i in transition_counts: \n",
    "        for key, value in i.items():\n",
    "            totals_t[key[0]] = totals_t.get(key[0], 0) + value\n",
    "    # get probability of each transition(ie MM, MD, MI)\n",
    "    prob_t = {}    \n",
    "    for key, value in trans_counts.items():\n",
    "        prob_t[key] = value/totals_t[key[0]] # laplace plus one rule maybe\n",
    "    \"\"\"\n",
    "    # get probability of state transitions for each position in sequence\n",
    "    prob_t = []\n",
    "    temp = {}\n",
    "    for trans_p in transition_counts:\n",
    "        tot = sum(trans_p.values())\n",
    "        for key, value in trans_p.items():\n",
    "            temp[key] = value/tot\n",
    "        prob_t.append(temp)\n",
    "        temp = {}\n",
    "    return state_prob, transition_counts, prob_t\n",
    "\n",
    "\n",
    "state_prob, transition_counts, prob_t = transition(states, seq, marked)\n",
    "print(\"state: {}, \\n transition_counts: {}, \\n prob_t: {}\".format(state_prob, transition_counts, prob_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d03546",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_count =  [{'MM': 4, 'MD': 1}, {'MM': 3, 'MD': 1, 'DD': 1}, {'MM': 2, 'IM': 2, 'MI': 1, 'ID': 1, 'II': 3, 'DI': 2}, {'MM': 4, 'DM': 1}], \n",
    "for i in t_count:\n",
    "    tot_m = sum(i.values()) if i.keys()[0][0] == \"M\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8365b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'M': {'A': 1.0}, 'I': {'A': 1.0}},\n",
       " {'M': {'G': 0.6666666666666666, 'T': 0.3333333333333333},\n",
       "  'I': {'G': 0.6666666666666666, 'T': 0.3333333333333333}},\n",
       " {'M': {'A': 0.8333333333333334, 'G': 0.16666666666666666},\n",
       "  'I': {'A': 0.8333333333333334, 'G': 0.16666666666666666}},\n",
       " {'M': {'A': 0.0, 'C': 1.0, 'G': 0.0, 'T': 0.0},\n",
       "  'I': {'A': 0.0, 'C': 1.0, 'G': 0.0, 'T': 0.0}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emission(states, seq, marked):\n",
    "    # get emission probabilities\n",
    "    # emission prob.\n",
    "    freq = []\n",
    "    temp = {'M':{}, 'I':{}}\n",
    "    nuc = {'A':0, 'C':0, 'G':0, 'T':0}\n",
    "    match_states = [ind for ind, ele in enumerate(marked) if ele == \"M\"] # gets indices of match states\n",
    "\n",
    "    for m in match_states[:-1]:\n",
    "        match_before = match_states[m] # index col of match state before insert states\n",
    "        match_after = match_states[m+1]        \n",
    "        # insert state(s)\n",
    "        if match_states[m]+1 != match_states[m+1]: \n",
    "            insert_nuc = seq.T[m:match_states[m+1]-1] # gets all the seq col. that are in the insert state\n",
    "            for col_i in insert_nuc:\n",
    "                for row_i in col_i:\n",
    "                    if row_i != '-':\n",
    "                        nuc[row_i] += 1\n",
    "            temp['I'] = dict(Counter(temp['I']) + Counter(nuc))\n",
    "            freq.append(temp)\n",
    "            temp = {'M':{}, 'I':{}}\n",
    "            nuc = {'A':0, 'C':0, 'G':0, 'T':0}\n",
    "        # match state\n",
    "        else:\n",
    "            for col_m in seq.T[m]:\n",
    "                for row_m in col_m:\n",
    "                    if row_m != '-':\n",
    "                        nuc[row_m] += 1\n",
    "            temp['M'] = dict(Counter(temp['M']) + Counter(nuc))\n",
    "            freq.append(temp)\n",
    "            temp = {'M':{}, 'I':{}}\n",
    "            nuc = {'A':0, 'C':0, 'G':0, 'T':0}\n",
    "    for col in seq.T[-1]:\n",
    "        for row in col:\n",
    "            if row != '-':\n",
    "                nuc[row] += 1\n",
    "    if marked[-1] == 'M':\n",
    "         temp['M'] = dict(Counter(nuc))\n",
    "    else:\n",
    "        temp['I'] = dict(Counter(nuc))\n",
    "    freq.append(temp)\n",
    "    \n",
    "    # get emission probabilities\n",
    "    emission_prob = []\n",
    "    temp_t = {}\n",
    "    temp_e = {}\n",
    "    for emis_p in freq:\n",
    "        tot = 0\n",
    "        temp_t = {}\n",
    "        temp_e = {}\n",
    "        for val in emis_p.values():\n",
    "            tot += sum(val.values())\n",
    "        for t_key, value in emis_p.items():\n",
    "            for e_key, e_val in value.items():\n",
    "                temp_e[e_key] = e_val/tot\n",
    "            temp_t[t_key] = temp_e        \n",
    "        emission_prob.append(temp_t)    \n",
    "    return emission_prob\n",
    "emission_prob = emission(states,seq,marked)\n",
    "emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08696b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(state_prob, prob_t, prob_e):\n",
    "    # format input into list of transition and emission states and probabilities as lists and list of lists\n",
    "    # ex: output: \n",
    "    # emission_states = [\"normal\", \"cold\", \"dizzy\"]\n",
    "    # transition_states = [\"Healthy\", \"Fever\"]\n",
    "    # state = [[0.6, 0.4]]\n",
    "    # transition = [[0.7,0.3], [0.4,0.6]] \n",
    "    # emission = [[0.5,0.3,0.1], [0.1,0.3,0.6]]\n",
    "    # seq = [\"normal\", \"cold\", \"dizzy\"]\n",
    "    \n",
    "    transition_states = [\"M\", \"D\", \"I\"]\n",
    "    transition = pd.DataFrame(columns=transition_states, index=transition_states)\n",
    "    # row is the state it came from, col is the state it's going to\n",
    "    for key, value in prob_t.items():\n",
    "        transition[key[0]][key[1]] = value   \n",
    "    emission_states = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    emission = pd.DataFrame(columns=emission_states, index=[\"M\", \"I\"])\n",
    "    for key, value in prob_e.items():\n",
    "        for key1, val1 in value.items():\n",
    "            emission.loc[key] = prob_e[key][key1]\n",
    "    state = [list(state_prob.values())]\n",
    "    df_state = pd.DataFrame(state, columns = ['M', 'D'])\n",
    "    \n",
    "    return df_state, transition, emission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9cc648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGC\n"
     ]
    }
   ],
   "source": [
    "consensus = \"\"\n",
    "for col in seq.T:\n",
    "    most_freq = Counter(col).most_common(1)[0][0]\n",
    "    if most_freq != \"-\":\n",
    "        consensus += most_freq\n",
    "print(consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d48fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(seq):\n",
    "    consensus = \"\"\n",
    "    for col in seq.T:\n",
    "        most_freq = Counter(col).most_common(1)[0][0]\n",
    "        if most_freq != \"-\":\n",
    "            consensus += most_freq\n",
    "    return consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43b2ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.33333333 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# find mutations\n",
    "# 1. loop through match states\n",
    "# 2. compare seq to consensus: use transition and emission probabilities to calc prob of mutation\n",
    "# 3. if prob of mutation is greater than 0.5, then it's a mutation\n",
    "def find_mutations(seq, prob_e):\n",
    "    marked, states = get_states(seq)\n",
    "    mutations = np.zeros(states.shape)\n",
    "    consensus = consensus(seq)\n",
    "    i = -1\n",
    "    for ind_m, m in enumerate(marked[1:]):\n",
    "        if m == \"M\": \n",
    "            i += 1 # index of match state in consensus)\n",
    "            for ind_n, n in enumerate(seq.T[ind_m]): # iterate down column of seq at index match state\n",
    "                if n != consensus[i] and n != '-':\n",
    "                    mutations[ind_n][ind_m] = prob_e[i]['M'][n]\n",
    "    return mutations\n",
    "\n",
    "mutations = find_mutations(seq, prob_e)\n",
    "print(mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a960ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pHMM.py import *\n",
    "hmm = pHMM.pHMM(pHMM_test.txt)\n",
    "hmm.filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c87d1865",
   "metadata": {},
   "source": [
    "# junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9da458",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m marked, states \u001b[38;5;241m=\u001b[39m get_states(seq)\n\u001b[1;32m----> 2\u001b[0m transition_counts, prob_t \u001b[38;5;241m=\u001b[39m transition(states, seq, marked)\n\u001b[0;32m      3\u001b[0m emission_counts \u001b[38;5;241m=\u001b[39m emission(states,seq, marked)\n\u001b[0;32m      4\u001b[0m states, prob_t, emission_counts, seq\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "marked, states = get_states(seq)\n",
    "transition_counts, prob_t = transition(states, seq, marked)\n",
    "emission_counts = emission(states,seq, marked)\n",
    "states, prob_t, emission_counts, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(states, seq, marked):\n",
    "    transition_counts = [] # length = # of match states\n",
    "    freq_t = {}\n",
    "    matches = 0\n",
    "    match_states = [ind for ind, ele in enumerate(marked) if ele == \"M\"] # gets indices of match states\n",
    "    match_states[-1] = match_states[-1]-1 # b/c length is +1 of seq, so last index will be out of index\n",
    "    state_prob = {}\n",
    "    for m in match_states[:-1]:\n",
    "        match_before = match_states[m] # index col of match state before insert states\n",
    "        match_after = match_states[m+1] \n",
    "        # state probability: M->state in first column\n",
    "        if m == match_states[0]:\n",
    "            for row in states.T[0]:\n",
    "                entry = (\"M{}\".format(row))\n",
    "                state_prob[entry] = state_prob.get(entry, 0) + 1\n",
    "            \n",
    "        # insert state(s)\n",
    "        elif match_states[m]+1 != match_states[m+1]: \n",
    "            insert_nuc = seq.T[m:match_states[m+1]] # gets all the seq col. that are in the insert state\n",
    "            insert_nuc = insert_nuc != \"-\" # bool array of all the nuc\n",
    "            for ind_r, row_i in enumerate(insert_nuc.T): \n",
    "                if np.any(row_i != False): # contains nuc. in insert col\n",
    "                    if  states[ind_r][match_before-1] == \"M\":\n",
    "                        freq_t[\"MI\"] = freq_t.get(\"MI\", 0) + 1\n",
    "                    if states[ind_r][match_after] == \"M\": # I->M\n",
    "                        freq_t[\"IM\"] = freq_t.get(\"IM\", 0) + 1\n",
    "                    elif states[ind_r][match_after] == \"D\": # I->D\n",
    "                        freq_t[\"ID\"] = freq_t.get(\"ID\", 0) + 1 \n",
    "                    # I->I\n",
    "                    for ind_c, col_c in enumerate(row_i[1:]):\n",
    "                        if row_i[ind_c-1] == True and col_c == True:\n",
    "                            freq_t[\"II\"] = freq_t.get(\"II\", 0) + 1 \n",
    "                else:\n",
    "                    if states[ind_r][match_before-1] == \"M\" and states[ind_r][match_after] == \"M\":\n",
    "                        freq_t[\"MM\"] = freq_t.get(\"MM\", 0) + 1                     \n",
    "\n",
    "         # match state\n",
    "        for j, row in enumerate(states.T[m]): # Iterate down col at corresponding index to match state in marked\n",
    "            if m == 0: # if the first col, assume the previous state was a match (the begin state)\n",
    "                entry = (\"M{}\".format(row))\n",
    "                freq_t[entry] = freq_t.get(entry, 0) + 1\n",
    "            else:\n",
    "                if states.T[m-1][j] == \"-\" or row == \"-\": # ignore gaps in insert state\n",
    "                    continue\n",
    "                entry = (\"{}{}\".format(states.T[m-1][j],row))\n",
    "                freq_t[entry] = freq_t.get(entry, 0) + 1\n",
    "        transition_counts.append(freq_t)\n",
    "        freq_t = {}\n",
    "    # if last column, assume transition is to match state?\n",
    "    for j, row in enumerate(states.T[-1]):\n",
    "        entry = (\"{}{}\".format(row,\"M\"))\n",
    "        freq_t[entry] = freq_t.get(entry, 0) + 1\n",
    "    transition_counts.append(freq_t)\n",
    "    freq_t = {}\n",
    "    for key, value in state_prob.items():\n",
    "        state_prob[key] = value/sum(state_prob.values())\n",
    "    # consolidate counts\n",
    "    trans_counts = {}\n",
    "    for i in transition_counts:\n",
    "        for key, value in i.items():\n",
    "            trans_counts[key] = trans_counts.get(key, 0) + value\n",
    "    # get totals of all the transitions from a state (M,D,I)\n",
    "    totals_t = {\"M\":0, \"D\":0, \"I\":0}\n",
    "    for i in transition_counts: \n",
    "        for key, value in i.items():\n",
    "            totals_t[key[0]] = totals_t.get(key[0], 0) + value\n",
    "    # get probability of each transition(ie MM, MD, MI)\n",
    "    prob_t = {}    \n",
    "    for key, value in trans_counts.items():\n",
    "        prob_t[key] = value/totals_t[key[0]] # laplace plus one rule maybe\n",
    "    return state_prob, transition_counts, prob_t\n",
    "    \n",
    "state_prob, transition_counts, prob_t = transition(states, seq, marked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        M     D         I\n",
      "M  0.8125  0.25  0.333333\n",
      "D   0.125  0.25  0.166667\n",
      "I  0.0625   0.5       0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transition_states = [\"M\", \"D\", \"I\"]\n",
    "transition = pd.DataFrame(columns=transition_states, index=transition_states)\n",
    "for key, value in prob_t.items():\n",
    "        transition[key[0]][key[1]] = value\n",
    "print(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e40c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6, 0.4]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144b10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     H    L\n",
       "0  0.5  0.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state = pd.DataFrame(state, columns = transition_states)\n",
    "df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd8305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "state = [[0.5, 0.5]]\n",
    "transition = [[0.5,0.4], [0.4,0.6]] \n",
    "transition_states = ['H', 'L']\n",
    "emission = [[0.2,0.3,0.3,0.2], [0.3,0.2,0.2,0.3]] # hidden states, row: A,C,G,T, col: H, L\n",
    "emission_states = ['A', 'C', 'G', 'T']\n",
    "seq = 'GGCACTGAA'\n",
    "\n",
    "def format_prob(state, transition, transition_states, emission, emission_states):\n",
    "    # input prob as list of lists and states as list of states\n",
    "    # output: pandas dataframe with states as indices\n",
    "    df_state = pd.DataFrame(state, columns = transition_states)\n",
    "    df_trans = pd.DataFrame(transition, index = transition_states, columns = transition_states)\n",
    "    df_em = pd.DataFrame(emission, index = transition_states, columns = emission_states,)\n",
    "    return df_state, df_trans, df_em\n",
    "\n",
    "state, transition, emission = format_prob(state, transition, transition_states, emission, emission_states)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a29630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'H', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'H', 'L', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'H', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('H', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'H', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'H', 'L', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'H', 'L', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'H', 'L', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'H', 'L', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'H', 'L', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'H', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'H', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'H', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'H', 'L', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'L', 'H', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'L', 'H', 'L'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'H'): 1,\n",
       " ('L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L'): 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_path = dict.fromkeys(list(itertools.product(transition_states, repeat=len(seq))), 1)\n",
    "all_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "394e5fa7",
   "metadata": {},
   "source": [
    "# Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3235ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "import math\n",
    "import gzip\n",
    "\n",
    "def count_kmers(filename, kmer_len, threshold):\n",
    "    # count kmers of all introns in file\n",
    "    # return list of all kmers in 2 lists (proximal/distal) and their counts\n",
    "    with gzip.open(filename, \"rt\") as f:\n",
    "        lines = f.readlines()\n",
    "        proximal = {}\n",
    "        distal = {}\n",
    "        for line in lines:\n",
    "            trans_id, start, end, strand, exp, seq = line.strip().split()\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            # add all kmers in seq to proximal/distal list based on position of kmer\n",
    "            for i in range(len(seq)-kmer_len+1):\n",
    "                if (start + i) < threshold:\n",
    "                    kmer = seq[i:i+kmer_len]\n",
    "                    if kmer not in proximal: proximal[kmer] = 1\n",
    "                    else: proximal[kmer] += 1\n",
    "                else:\n",
    "                    if kmer not in distal: distal[kmer] = 1\n",
    "                    else: distal[kmer] += 1    \n",
    "    return proximal, distal\n",
    "filename = '../datacore/project_imeter/at_ime_master.txt.gz'\n",
    "kmer_len = 4\n",
    "threshold = 400\n",
    "proximal, distal = count_kmers(filename, kmer_len, threshold)\n",
    "p_total = sum(proximal.values())\n",
    "d_total = sum(distal.values())\n",
    "\n",
    "# get list of kmers with high expression values\n",
    "# calculate nucleotide composition of high expression kmers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a7c186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome: CCCAAC, Fitness: 2.853 Chromosome: GCAGGC, Fitness: -3.5\n",
      "Chromosome: GGCGAT, Fitness: 3.177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3190787037037037"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GENES = \"ACGT\"\n",
    "class Individual():\n",
    "    def __init__(self, proximal, distal, kmer_len, chr_len):\n",
    "        self.kmer_len = kmer_len\n",
    "        self.chr_len = chr_len\n",
    "        self.chromosome = self.create_genome()\n",
    "        self.proximal = proximal\n",
    "        self.distal = distal \n",
    "        self.p_total = sum(proximal.values())\n",
    "        self.d_total = sum(distal.values())\n",
    "        self.fitness = self.calc_fitness()        \n",
    "\n",
    "    def create_genome(self):\n",
    "        chromosome = \"\".join(random.choice(GENES) for _ in range(self.chr_len))\n",
    "        return chromosome\n",
    "    \n",
    "    def calc_fitness(self):\n",
    "        fitness = 0\n",
    "        for i in range(len(self.chromosome)-self.kmer_len+1):\n",
    "            kmer = self.chromosome[i:i+self.kmer_len]\n",
    "            if kmer not in self.proximal: \n",
    "                prob_p = 1 / self.p_total\n",
    "            else:\n",
    "                prob_p = self.proximal[kmer] / self.p_total\n",
    "            if kmer not in self.distal: \n",
    "                prob_d = 1 / self.d_total\n",
    "            else:\n",
    "                prob_d = self.distal[kmer] / self.d_total\n",
    "            fitness += math.log2(prob_p/prob_d) \n",
    "        return fitness \n",
    "\n",
    "    def mate(self, partner, operator = \"opc\", mutation_rate=0.01):\n",
    "        offspring1 = Individual(self.proximal, self.distal, self.kmer_len, self.chr_len)\n",
    "        offspring2 = Individual(self.proximal, self.distal, self.kmer_len, self.chr_len)\n",
    "        cutoff = random.randint(0, len(self.chromosome))\n",
    "        offspring = \"\"\n",
    "        if operator == \"opc\":\n",
    "            offspring1.chromosome = self.chromosome[:cutoff] + partner.chromosome[cutoff:]\n",
    "            offspring2.chromosome = partner.chromosome[:cutoff] + self.chromosome[cutoff:]\n",
    "        elif operator == \"upc\":\n",
    "            for i in range(self.chr_len):\n",
    "                if random.randint(0, 1):\n",
    "                    offspring1.chromosome += self.chromosome[i]\n",
    "                    offspring2.chromosome += partner.chromosome[i]\n",
    "                else:\n",
    "                    offspring1.chromosome += partner.chromosome[i]\n",
    "                    offspring2.chromosome += self.chromosome[i]\n",
    "        # mutation\n",
    "        for i in range(len(offspring1.chromosome)):\n",
    "            if random.randint(0, 100) > mutation_rate:\n",
    "                offspring1.chromosome = offspring1.chromosome[:i] + random.choice(GENES) + offspring1.chromosome[i+1:]\n",
    "            if random.randint(0, 100) > mutation_rate:\n",
    "                offspring2.chromosome = offspring2.chromosome[:i] + random.choice(GENES) + offspring2.chromosome[i+1:]\n",
    "\n",
    "        offspring1.fitness = offspring1.calc_fitness()\n",
    "        offspring2.fitness = offspring2.calc_fitness()\n",
    "        \n",
    "        return offspring1, offspring2\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Chromosome: {self.chromosome}, Fitness: {self.fitness:.4g}\"\n",
    "def gc_content(seq):\n",
    "    s = [*seq]\n",
    "    return (s.count(\"G\") + s.count(\"C\")) / len(s)\n",
    "  \n",
    "x = Individual(proximal, distal, kmer_len, 6)\n",
    "y = Individual(proximal, distal, kmer_len, 6)\n",
    "o1, o2 = x.mate(y)\n",
    "print(o1, o2)\n",
    "print(x)\n",
    "(1-abs(gc_content(x.chromosome)-0.35))**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20721216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual():\n",
    "    def __init__(self, proximal, distal, kmer_len, chr_len):\n",
    "        self.kmer_len = kmer_len\n",
    "        self.chr_len = chr_len\n",
    "        self.chromosome = self.create_genome()\n",
    "        self.proximal = proximal\n",
    "        self.distal = distal \n",
    "        self.p_total = sum(proximal.values())\n",
    "        self.d_total = sum(distal.values())\n",
    "        self.fitness = self.calc_fitness()        \n",
    "\n",
    "    def create_genome(self):\n",
    "        chromosome = \"\".join(random.choice(GENES) for _ in range(self.chr_len))\n",
    "        return chromosome\n",
    "    \n",
    "    def calc_fitness(self):\n",
    "        fitness = 0\n",
    "        for i in range(len(self.chromosome)-self.kmer_len+1):\n",
    "            kmer = self.chromosome[i:i+self.kmer_len]\n",
    "            if kmer not in self.proximal: \n",
    "                prob_p = 1 / self.p_total\n",
    "            else:\n",
    "                prob_p = self.proximal[kmer] / self.p_total\n",
    "            if kmer not in self.distal: \n",
    "                prob_d = 1 / self.d_total\n",
    "            else:\n",
    "                prob_d = self.distal[kmer] / self.d_total\n",
    "            fitness += math.log2(prob_p/prob_d) \n",
    "        return fitness \n",
    "\n",
    "    def mate(self, partner, operator = \"opc\", mutation_rate=0.01):\n",
    "        offspring = Individual(self.proximal, self.distal, self.kmer_len, self.chr_len)\n",
    "        cutoff = random.randint(0, len(self.chromosome))\n",
    "        if operator == \"opc\":\n",
    "            offspring.chromosome = self.chromosome[:cutoff] + partner.chromosome[cutoff:]\n",
    "        elif operator == \"upc\":\n",
    "            for i in range(self.chr_len):\n",
    "                if random.randint(0, 1):\n",
    "                    offspring.chromosome += self.chromosome[i]\n",
    "                else:\n",
    "                    offspring.chromosome += partner.chromosome[i]\n",
    "        # mutation\n",
    "        for i in range(len(offspring.chromosome)):\n",
    "            if random.randint(0, 100) > mutation_rate:\n",
    "                offspring.chromosome = offspring.chromosome[:i] + random.choice(GENES) + offspring.chromosome[i+1:]\n",
    "            \n",
    "        offspring.fitness = offspring.calc_fitness()        \n",
    "        return offspring\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Chromosome: {self.chromosome}, Fitness: {self.fitness:.4g}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86561ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: 49.977778560580006\n",
      "Generation 2: 55.70478364689321\n",
      "Generation 3: 55.09371557636653\n",
      "Generation 4: 58.16691226859525\n",
      "Generation 5: 58.854055513481214\n",
      "Generation 6: 54.413983432922336\n",
      "Generation 7: 57.515409478240166\n",
      "Generation 8: 60.03725117480729\n",
      "Generation 9: 55.520842960705096\n",
      "Generation 10: 58.081556328175175\n",
      "Generation 11: 57.06225182537514\n",
      "Generation 12: 59.39979689400115\n",
      "Generation 13: 61.006987399251415\n",
      "Generation 14: 60.65094276080863\n",
      "Generation 15: 61.058112078594355\n",
      "Generation 16: 59.725798070864045\n",
      "Generation 17: 60.81932233960912\n",
      "Generation 18: 62.01556554629775\n",
      "Generation 19: 60.15611354970741\n",
      "Generation 20: 62.12297709521267\n",
      "Generation 21: 60.27452930784515\n",
      "Generation 22: 63.47444271493602\n",
      "Generation 23: 61.31728124304542\n",
      "Generation 24: 62.706370306900375\n",
      "Generation 25: 60.95997265299562\n",
      "Generation 26: 64.77239303602838\n",
      "Generation 27: 63.37130391542556\n",
      "Generation 28: 63.237375509978875\n",
      "Generation 29: 65.08227541271312\n",
      "Generation 30: 63.729570247075074\n",
      "Generation 31: 63.77146330288288\n",
      "Generation 32: 64.5265565254445\n",
      "Generation 33: 64.83315734519489\n",
      "Generation 34: 63.01307603081221\n",
      "Generation 35: 65.21505468619542\n",
      "Generation 36: 65.90603827142323\n",
      "Generation 37: 64.8972820761123\n",
      "Generation 38: 62.652422109091695\n",
      "Generation 39: 63.60872767682852\n",
      "Generation 40: 65.09861016897669\n",
      "Generation 41: 77.30544808664261\n",
      "Generation 42: 74.10790630649542\n",
      "Generation 43: 73.80853596417286\n",
      "Generation 44: 74.41922059171584\n",
      "Generation 45: 78.56471767470941\n",
      "Generation 46: 75.92492490446968\n",
      "Generation 47: 76.6387341060197\n",
      "Generation 48: 72.01619656768025\n",
      "Generation 49: 74.97781979777614\n",
      "Generation 50: 75.55849074861277\n",
      "Generation 51: 75.65628041771096\n",
      "Generation 52: 76.89284382054457\n",
      "Generation 53: 73.60668946200279\n",
      "Generation 54: 75.84236962241943\n",
      "Generation 55: 74.6372655830942\n",
      "Generation 56: 75.35654929043628\n",
      "Generation 57: 75.52535967341828\n",
      "Generation 58: 76.71887460828806\n",
      "Generation 59: 78.13225236961009\n",
      "Generation 60: 76.91939391618224\n",
      "Generation 61: 79.39266873703903\n",
      "Generation 62: 79.11411292298823\n",
      "Generation 63: 78.74294731145966\n",
      "Generation 64: 87.49467295681228\n",
      "Generation 65: 102.61984738013385\n",
      "Generation 66: 98.47297633250217\n",
      "Generation 67: 99.21296413442442\n",
      "Generation 68: 98.59369560920074\n",
      "Generation 69: 100.44563801942382\n",
      "Generation 70: 100.5221571829996\n",
      "Generation 71: 98.56523813682425\n",
      "Generation 72: 101.62186033016705\n",
      "Generation 73: 114.51401927843888\n",
      "Generation 74: 115.40508505463835\n",
      "Generation 75: 111.8155869594187\n",
      "Generation 76: 106.57177576237169\n",
      "Generation 77: 110.3115389169167\n",
      "Generation 78: 109.39192914483864\n",
      "Generation 79: 110.81314154091163\n",
      "Generation 80: 111.49947433124382\n",
      "Generation 81: 105.62873713865109\n",
      "Generation 82: 111.0729040709122\n",
      "Generation 83: 113.13717086374211\n",
      "Generation 84: 111.7135368515043\n",
      "Generation 85: 104.62918368821259\n",
      "Generation 86: 111.75515175867645\n",
      "Generation 87: 111.8203281330258\n",
      "Generation 88: 118.41752248823174\n",
      "Generation 89: 118.93268843294814\n",
      "Generation 90: 120.59591517136806\n",
      "Generation 91: 119.0806700163302\n",
      "Generation 92: 122.24220517101695\n",
      "Generation 93: 121.34663803672954\n",
      "Generation 94: 118.32279816449156\n",
      "Generation 95: 118.6413309185092\n",
      "Generation 96: 121.33660279873801\n",
      "Generation 97: 118.20973590329041\n",
      "Generation 98: 118.00320637468732\n",
      "Generation 99: 118.97062775793209\n",
      "Generation 100: 120.1639641245288\n"
     ]
    }
   ],
   "source": [
    "class Population():\n",
    "    def __init__(self, proximal, distal, kmer_len, chr_len, gen_size, gen_len):\n",
    "        self.gen_size = gen_size\n",
    "        self.gen_len = gen_len\n",
    "        self.kmer_len = kmer_len\n",
    "        self.chr_len = chr_len\n",
    "        self.proximal = proximal\n",
    "        self.distal = distal \n",
    "        self.individuals = []\n",
    "\n",
    "    def populate(self):\n",
    "        for i in range(self.gen_size):\n",
    "            self.individuals.append(Individual(self.proximal, self.distal, self.kmer_len, self.chr_len))\n",
    "            \n",
    "    def select_parents(self, individuals, k):\n",
    "        # Can't use Fitness Proportionate Selection b/c negative fitness values (log odds)\n",
    "        # Tournament selection\n",
    "        pop = individuals.copy()\n",
    "        select = []\n",
    "        for i in range(2):\n",
    "            turn = []\n",
    "            for j in range(k):\n",
    "                turn.append(pop[random.randint(0, len(pop)-1)])\n",
    "            parent = max(turn, key = lambda x: x.fitness)\n",
    "            pop.remove(parent)\n",
    "            select.append(parent)\n",
    "        return select\n",
    "    \n",
    "    def selection(self, proportion, k):\n",
    "        # Fitness Based Selection\n",
    "        for i in range(int(len(self.individuals)*proportion)):\n",
    "            self.individuals.remove(min(self.individuals, key = lambda x: x.fitness))\n",
    "            parents = self.select_parents(self.individuals, k)\n",
    "            o = parents[0].mate(parents[1])\n",
    "            self.individuals.append(o)\n",
    "    def evolve(self):\n",
    "        for i in range(self.gen_len):\n",
    "            self.selection(0.5, 2)\n",
    "            print(f\"Generation {i+1}: {sum([i.fitness for i in self.individuals])}\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Individuals: {self.individuals}\"\n",
    "    \n",
    "x = Population(proximal, distal, 4, 6, 10, 100)\n",
    "x.populate()\n",
    "x.evolve()\n",
    "\n",
    "# sorted_indiv = sorted(x.individuals, key = lambda x: x.fitness, reverse=True)\n",
    "# print(x.individuals, sum([i.fitness for i in x.individuals]))\n",
    "# x.selection(0.5, 2)\n",
    "# print(x.individuals, sum([i.fitness for i in x.individuals]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44c0fd22",
   "metadata": {},
   "source": [
    "# Stochastic Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae75cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e1f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">I 1..150725\n",
      "\n",
      "GCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGC\n",
      "\n",
      "CTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCT\n",
      "\n",
      "AAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAA\n",
      "\n",
      "GCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGC\n",
      "\n",
      "CTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCT\n",
      "\n",
      "AAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAA\n",
      "\n",
      "GCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGC\n",
      "\n",
      "CTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAGCCT\n",
      "\n",
      "AAGCCTAAGCCTAAGCCTAAGCCTAAGCCTAAAAAATTGAGATAAGAAAA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = \"./tests/1pct_elegans.fa\"\n",
    "with open(file, \"rt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:10]:\n",
    "        print(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48c99b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gene',\n",
       " 'pre_miRNA',\n",
       " 'miRNA',\n",
       " 'exon',\n",
       " 'possible_base_call_error',\n",
       " 'ncRNA',\n",
       " 'three_prime_UTR',\n",
       " 'nc_primary_transcript',\n",
       " 'mRNA',\n",
       " 'pseudogenic_transcript',\n",
       " 'CDS',\n",
       " 'tRNA',\n",
       " 'circular_ncRNA',\n",
       " 'piRNA',\n",
       " 'base_call_error_correction',\n",
       " 'five_prime_UTR',\n",
       " 'intron',\n",
       " 'snoRNA',\n",
       " 'pseudogenic_tRNA',\n",
       " 'transposable_element',\n",
       " 'transcript_region',\n",
       " 'transcription_end_site']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"./tests/1pct_elegans.gff3\"\n",
    "with open(file, \"rt\") as f:\n",
    "    lines = f.readlines()\n",
    "    start = []\n",
    "    end = []\n",
    "    states = []\n",
    "    for line in lines:\n",
    "        states.append(line.strip().split()[2])\n",
    "        start.append(int(line.strip().split()[3]))\n",
    "        end.append(int(line.strip().split()[4]))\n",
    "\n",
    "# get unique states \n",
    "transition_states = list(set(states))\n",
    "transition_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ab5b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rain': 0.5, 'no_rain': 0.5},\n",
       " {'rain': {'rain': 0.7, 'no_rain': 0.3},\n",
       "  'no_rain': {'rain': 0.3, 'no_rain': 0.7}},\n",
       " {'rain': {'umbrella': 0.9, 'no_umbrella': 0.1},\n",
       "  'no_rain': {'umbrella': 0.2, 'no_umbrella': 0.8}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {}\n",
    "transition = {}\n",
    "emission = {}\n",
    "\n",
    "with open(\"./tests/stoch_hmm.json\") as f:\n",
    "    x = json.load(f)\n",
    "    for i in range(x['states']):\n",
    "        temp = x['state'][i]\n",
    "        state[temp['name']] = temp['init']\n",
    "        transition[temp['name']] = temp['transition']\n",
    "        emission[temp['name']] = temp['emission']\n",
    "\n",
    "state, transition, emission\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5b0dd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './stoch_hmm.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bunan\\shared_folder\\korflab\\viterbi\\stochastic_viterbi\\random.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m path, prev_prob\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m transition_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./stoch_hmm.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m viterbi(transition_file, \u001b[39m\"\u001b[39;49m\u001b[39mACGT\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\bunan\\shared_folder\\korflab\\viterbi\\stochastic_viterbi\\random.ipynb Cell 36\u001b[0m in \u001b[0;36mviterbi\u001b[1;34m(transition_file, seq, log)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m transition \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m emission \u001b[39m=\u001b[39m {}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(transition_file) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     x \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bunan/shared_folder/korflab/viterbi/stochastic_viterbi/random.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x[\u001b[39m'\u001b[39m\u001b[39mstates\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './stoch_hmm.json'"
     ]
    }
   ],
   "source": [
    "def viterbi(transition_file, seq, log=1):\n",
    "    state = {}\n",
    "    transition = {}\n",
    "    emission = {}\n",
    "    with open(transition_file) as f:\n",
    "        x = json.load(f)\n",
    "        for i in range(x['states']):\n",
    "            temp = x['state'][i]\n",
    "            state[temp['name']] = temp['init']\n",
    "            transition[temp['name']] = temp['transition']\n",
    "            emission[temp['name']] = temp['emission']\n",
    "        if len(transition) != len(emission):\n",
    "            raise ValueError(\"Transition and emission matrices must be the same length\")\n",
    "        probability = 1\n",
    "        path = []\n",
    "        if type(seq) == str:\n",
    "            seq = [*seq]\n",
    "        for s,i in zip(seq, range(len(seq))):\n",
    "            if i == 0: # if first in seq, use state prob.\n",
    "                prob1 = {}\n",
    "                for st in state:\n",
    "                    prob1[st] = float(state[st] * emission[st][s]) \n",
    "                t_state = max(prob1, key=prob1.get)\n",
    "                path.append(t_state) # add max probability to path\n",
    "                if log == 1:\n",
    "                    prev_prob = math.log2(prob1[path[0]])\n",
    "                else:\n",
    "                    prev_prob = prob1[path[0]]\n",
    "                prev_state = t_state\n",
    "            else:\n",
    "                prob = {}           \n",
    "                for t in transition:      \n",
    "                    if log == 1:\n",
    "                        prob[t] = prev_prob +  math.log2(transition[prev_state][t] * emission[t][s])\n",
    "                    else:\n",
    "                        prob[t] = prev_prob * (transition[prev_state][t] * emission[t][s])\n",
    "                x = max(prob, key=prob.get)\n",
    "                path.append(x)\n",
    "                prev_prob = prob[x]\n",
    "                prev_state = x\n",
    "    return path, prev_prob\n",
    "transition_file = \"./tests/stoch_hmm.json\"\n",
    "viterbi(transition_file, \"ACGT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4af19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [*'ACGT']\n",
    "emission = {'AT': {'A': 0.3, 'C': 0.2, 'G': 0.2, 'T': 0.3},\n",
    "  'NT': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
    "  'GC': {'A': 0.2, 'C': 0.3, 'G': 0.3, 'T': 0.2}}\n",
    "\n",
    "emission['AT']['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc522d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(seq_file, gff_file):\n",
    "    with open(seq_file, \"rt\") as f:\n",
    "        seqs = f.readlines()[1].strip()\n",
    "    with open(gff_file, \"rt\") as f:\n",
    "        lines = f.readlines()\n",
    "        gff = {}\n",
    "        start = []\n",
    "        end = []\n",
    "        states = []\n",
    "        for line in lines:\n",
    "            if line.strip().split()[0] not in gff:\n",
    "                gff[line.strip().split()[0]] = {\"states\": [], \"start\": [], \"end\": []}\n",
    "            gff[line.strip().split()[0]][\"states\"].append(line.strip().split()[2])\n",
    "            gff[line.strip().split()[0]][\"start\"].append(int(line.strip().split()[3]))\n",
    "            gff[line.strip().split()[0]][\"end\"].append(int(line.strip().split()[4]))\n",
    "        # get unique states\n",
    "    transition_states = list(set(states))\n",
    "    for seq in seqs:\n",
    "        seq = [*seq]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pre_miRNA',\n",
       " 'gene',\n",
       " 'pseudogenic_transcript',\n",
       " 'nc_primary_transcript',\n",
       " 'pseudogenic_tRNA',\n",
       " 'ncRNA',\n",
       " 'base_call_error_correction',\n",
       " 'snoRNA',\n",
       " 'circular_ncRNA',\n",
       " 'possible_base_call_error',\n",
       " 'miRNA',\n",
       " 'CDS',\n",
       " 'exon',\n",
       " 'transcript_region',\n",
       " 'intron',\n",
       " 'transposable_element',\n",
       " 'three_prime_UTR',\n",
       " 'five_prime_UTR',\n",
       " 'transcription_end_site',\n",
       " 'mRNA',\n",
       " 'tRNA',\n",
       " 'piRNA']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gff_file = \"./tests/1pct_elegans.gff3\"\n",
    "with open(gff_file, \"rt\") as f:\n",
    "    lines = f.readlines()\n",
    "    gff = {}\n",
    "    for line in lines:\n",
    "        if line.strip().split()[0] not in gff:\n",
    "            gff[line.strip().split()[0]] = {\"states\": [], \"start\": [], \"end\": []}\n",
    "        gff[line.strip().split()[0]][\"states\"].append(line.strip().split()[2])\n",
    "        gff[line.strip().split()[0]][\"start\"].append(int(line.strip().split()[3]))\n",
    "        gff[line.strip().split()[0]][\"end\"].append(int(line.strip().split()[4]))\n",
    "    # get unique states\n",
    "states = []\n",
    "for i in gff:\n",
    "    states += gff[i][\"states\"]\n",
    "transition_states = list(set(states))\n",
    "transition_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf5c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">seq-1\n",
      "ACACGTGACCACTGGCGTACCTAAGGGCCAGGGAATGCTGCTGACATGATGGGGGTGGCGAGGCCAAGGTCCCA\n",
      ">seq-2\n",
      "AAATACCTGCACAGTATGTATGATAAATGCATATGATAAAGTAAAAAAAAAAATAGCACACACTGAAAGAAAGCCAACAGAAGAGGGCACTGGGCATGGGCCAGGGAGGGCAAGAATTGGGATGGGGACATGGAGGAGC\n",
      ">seq-3\n",
      "GTCTGGACTTCGCTGTGAAAGACACAGGCCCTCATGTACGTCCAGGATGCGGTGACAGCGAGGCTTGCAGGAGACAGGTCCCTGCTGTGTGGGGGTGAAGCTGGAGGCAAGATGATGCCTGGAGCTAAGAGATGGTCACAGGAAATCCGGCAAGAATTAACGAGGACTGGACAGTGACAGGCAGGCCAAAGAGTGAGAGGAACTTCACTGGCAAGAGCCAACAGGGCTTGTTGATTTAGGAGAGGAGACAAAGGACTGAGGGGTTTGGGGGCTGGGGCCTGGGAGGGTGGAGAAGCCACTGTCTGCAT\n",
      ">seq-4\n",
      "AGCACAGGTGCCTGCTGAGTCCCATAGACCCACTAATGGCCCACCAGGACCAACCAGG\n",
      ">seq-5\n",
      "AGAGAACGTGCTGACTGCGCTCGTTTGGAAAGGCCTCATGGCCAAAGG\n"
     ]
    }
   ],
   "source": [
    "import gzip \n",
    "\n",
    "with open(\"../datacore/project_rloop/235.fa\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:10]:\n",
    "        print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58816fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exon': {'A': 0.3, 'C': 0.2, 'G': 0.2, 'T': 0.3},\n",
       " 'intron': {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25},\n",
       " 'utr': {'A': 0.2, 'C': 0.3, 'G': 0.3, 'T': 0.2}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_file = \"./stoch_hmm.json\"\n",
    "state = {}\n",
    "transition = {}\n",
    "emission = {}\n",
    "with open(transition_file) as f:\n",
    "    x = json.load(f)\n",
    "    for i in range(x['states']):\n",
    "        temp = x['state'][i]\n",
    "        state[temp['name']] = temp['init']\n",
    "        transition[temp['name']] = temp['transition']\n",
    "        emission[temp['name']] = temp['emission']\n",
    "\n",
    "emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_viterbi(json_file, seq, log=1):\n",
    "    state = {}\n",
    "    transition = {}\n",
    "    emission = {}\n",
    "    with open(\"./stoch_hmm.json\") as f:\n",
    "        x = json.load(f)\n",
    "        for i in range(x['states']):\n",
    "            temp = x['state'][i]\n",
    "            state[temp['name']] = temp['init']\n",
    "            transition[temp['name']] = temp['transition']\n",
    "            emission[temp['name']] = temp['emission']\n",
    "        # set illegal transition to zero probability\n",
    "        for trans in transition:\n",
    "            if set(transition.keys()) != set(transition[trans].keys()):\n",
    "                # check for values in transition.keys that are not in transition[trans].keys() and add to transition[trans].keys()\n",
    "                for i in set(transition.keys()) - set(transition[trans].keys()):\n",
    "                    transition[trans][i] = 0\n",
    "    if type(seq) == str:\n",
    "        seq = [*seq]\n",
    "    # Calculate forward probability\n",
    "    forward = dict((key, []) for key in transition.keys())\n",
    "    for o in seq:\n",
    "        for trans in transition:\n",
    "            if o == seq[0]:\n",
    "                if emission[trans][o] == 0 or state[trans] == 0: \n",
    "                    fw = 0\n",
    "                else:\n",
    "                    fw = math.log10(emission[trans][o]) + math.log10(state[trans])\n",
    "            else:\n",
    "                fw = 0\n",
    "                for prev in transition[trans]:\n",
    "                    if transition[prev][trans] != 0:\n",
    "                        fw += math.exp(forward[prev][-1] + math.log10(transition[prev][trans]))\n",
    "                fw = math.log10(fw) + math.log10(emission[trans][o])\n",
    "            forward[trans].append(fw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc789a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exon': [0, -0.6011446912330125, 0, -0.6011446912330125],\n",
       " 'intron': [-0.6020599913279624,\n",
       "  -0.8117139066635318,\n",
       "  -0.6020599913279624,\n",
       "  -0.8117139066635318],\n",
       " 'utr': [0, -0.5011246726930683, 0, -0.5011246726930683]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {}\n",
    "transition = {}\n",
    "emission = {}\n",
    "\n",
    "with open(\"./stoch_hmm.json\") as f:\n",
    "    x = json.load(f)\n",
    "    for i in range(x['states']):\n",
    "        temp = x['state'][i]\n",
    "        state[temp['name']] = temp['init']\n",
    "        transition[temp['name']] = temp['transition']\n",
    "        emission[temp['name']] = temp['emission']\n",
    "    # set illegal transition to zero probability\n",
    "    for trans in transition:\n",
    "        if set(transition.keys()) != set(transition[trans].keys()):\n",
    "            # check for values in transition.keys that are not in transition[trans].keys() and add to transition[trans].keys()\n",
    "            for i in set(transition.keys()) - set(transition[trans].keys()):\n",
    "                transition[trans][i] = 0\n",
    "\n",
    "\n",
    "state, transition, emission\n",
    "\n",
    "\n",
    "seq = \"ACAC\"\n",
    "path = []\n",
    "if type(seq) == str:\n",
    "    seq = [*seq]\n",
    "# Calculate forward probability\n",
    "forward = dict((key, []) for key in transition.keys())\n",
    "for o in seq:\n",
    "    for trans in transition:\n",
    "        fw = 0\n",
    "        if o == seq[0]:\n",
    "            if not(emission[trans][o] == 0 or state[trans] == 0):\n",
    "                fw = math.log10(emission[trans][o]) + math.log10(state[trans])\n",
    "        else:\n",
    "            for prev in transition[trans]:\n",
    "                if transition[prev][trans] != 0:\n",
    "                    fw += math.exp(forward[prev][-1] + math.log10(transition[prev][trans]))\n",
    "            fw = math.log10(fw) + math.log10(emission[trans][o])\n",
    "        forward[trans].append(fw)\n",
    "\n",
    "# backward probability\n",
    "backward = dict((key, []) for key in transition.keys())\n",
    "for o in seq[::-1]:\n",
    "    for trans in transition:\n",
    "        if o == seq[-1]:\n",
    "            pass\n",
    "        \n",
    "\n",
    "forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c337df",
   "metadata": {},
   "source": [
    "### Scaling factor (Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63516889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4bf323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rain': 0.5, 'no_rain': 0.5},\n",
       " {'rain': {'rain': 0.7, 'no_rain': 0.3},\n",
       "  'no_rain': {'rain': 0.3, 'no_rain': 0.7}},\n",
       " {'rain': {'umbrella': 0.9, 'no_umbrella': 0.1},\n",
       "  'no_rain': {'umbrella': 0.2, 'no_umbrella': 0.8}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize vectors\n",
    "state = {}\n",
    "transition = {}\n",
    "emission = {}\n",
    "\n",
    "with open(\"./tests/stoch_hmm.json\") as f:\n",
    "    x = json.load(f)\n",
    "    for i in range(x['states']):\n",
    "        temp = x['state'][i]\n",
    "        state[temp['name']] = temp['init']\n",
    "        transition[temp['name']] = temp['transition']\n",
    "        emission[temp['name']] = temp['emission']\n",
    "    # set illegal transition to zero probability\n",
    "    for trans in transition:\n",
    "        if set(transition.keys()) != set(transition[trans].keys()):\n",
    "            # check for values in transition.keys that are not in transition[trans].keys() and add to transition[trans].keys()\n",
    "            for i in set(transition.keys()) - set(transition[trans].keys()):\n",
    "                transition[trans][i] = 0\n",
    "\n",
    "\n",
    "state, transition, emission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0894b5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rain': 0.5, 'no_rain': 0.5},\n",
       " {'rain': 0.8181818181818181, 'no_rain': 0.18181818181818182},\n",
       " {'rain': 0.883357041251778, 'no_rain': 0.1166429587482219},\n",
       " {'rain': 0.7991614429822741, 'no_rain': 0.20083855701772588},\n",
       " {'rain': 0.8700720584642331, 'no_rain': 0.12992794153576687},\n",
       " {'rain': 0.9184993701915494, 'no_rain': 0.0815006298084507}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of size seq\n",
    "seq = \"umbrella, umbrella, no_umbrella, umbrella, umbrella\"\n",
    "path = []\n",
    "seq = seq.split(\", \")\n",
    "# Calculate forward probability\n",
    "forward = list(dict((key, 0) for key in transition.keys()) for i in range(len(seq)))\n",
    "for ind, o in enumerate(seq):\n",
    "    for trans in transition:\n",
    "        fw = 0\n",
    "        if ind == 0:\n",
    "            if not(emission[trans][o] == 0 or state[trans] == 0):\n",
    "                fw = emission[trans][o] * state[trans]\n",
    "        else:\n",
    "            for prev in transition[trans]:\n",
    "                if transition[prev][trans] != 0:\n",
    "                    fw += forward[ind-1][trans] * transition[prev][trans] * emission[prev][o]\n",
    "        forward[ind][trans] = fw\n",
    "    # normalize\n",
    "    tot = sum(forward[ind].values())\n",
    "    for t in forward[ind]: \n",
    "        forward[ind][t] /= tot\n",
    "forward.insert(0, dict((key, state[key]) for key in transition.keys()))\n",
    "\n",
    "\n",
    "forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23658d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rain': {'rain': 0.7, 'no_rain': 0.3},\n",
       " 'no_rain': {'rain': 0.3, 'no_rain': 0.7}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e8b758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain rain 0.8181818181818181 0.7 0.9\n",
      "rain no_rain 0.18181818181818182 0.3 0.9\n",
      "no_rain rain 0.8181818181818181 0.3 0.2\n",
      "no_rain no_rain 0.18181818181818182 0.7 0.2\n",
      "rain rain 0.883357041251778 0.7 0.1\n",
      "rain no_rain 0.1166429587482219 0.3 0.1\n",
      "no_rain rain 0.883357041251778 0.3 0.8\n",
      "no_rain no_rain 0.1166429587482219 0.7 0.8\n",
      "rain rain 0.19066793972352525 0.7 0.9\n",
      "rain no_rain 0.8093320602764748 0.3 0.9\n",
      "no_rain rain 0.19066793972352525 0.3 0.2\n",
      "no_rain no_rain 0.8093320602764748 0.7 0.2\n",
      "rain rain 0.730794004584982 0.7 0.9\n",
      "rain no_rain 0.26920599541501794 0.3 0.9\n",
      "no_rain rain 0.730794004584982 0.3 0.2\n",
      "no_rain no_rain 0.26920599541501794 0.7 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'rain': 0.8181818181818181, 'no_rain': 0.18181818181818182},\n",
       " {'rain': 0.883357041251778, 'no_rain': 0.1166429587482219},\n",
       " {'rain': 0.19066793972352525, 'no_rain': 0.8093320602764748},\n",
       " {'rain': 0.730794004584982, 'no_rain': 0.26920599541501794},\n",
       " {'rain': 0.8673388895754847, 'no_rain': 0.13266111042451528}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_viterbi(json_file, seq, log=1):\n",
    "    state = {}\n",
    "    transition = {}\n",
    "    emission = {}\n",
    "    with open(json_file) as f:\n",
    "        x = json.load(f)\n",
    "        for i in range(x['states']):\n",
    "            temp = x['state'][i]\n",
    "            state[temp['name']] = temp['init']\n",
    "            transition[temp['name']] = temp['transition']\n",
    "            emission[temp['name']] = temp['emission']\n",
    "        # set illegal transition to zero probability\n",
    "        for trans in transition:\n",
    "            if set(transition.keys()) != set(transition[trans].keys()):\n",
    "                # check for values in transition.keys that are not in transition[trans].keys() and add to transition[trans].keys()\n",
    "                for i in set(transition.keys()) - set(transition[trans].keys()):\n",
    "                    transition[trans][i] = 0\n",
    "    if type(seq) == str:\n",
    "        seq = seq.split(\", \")\n",
    "    # Calculate forward probability\n",
    "    # forward = dict((key, []) for key in transition.keys())\n",
    "    # for o in seq:\n",
    "    #     for trans in transition:\n",
    "    #         if o == seq[0]:\n",
    "    #             if emission[trans][o] == 0 or state[trans] == 0: \n",
    "    #                 fw = 0\n",
    "    #             else:\n",
    "    #                 fw = math.log10(emission[trans][o]) + math.log10(state[trans])\n",
    "    #         else:\n",
    "    #             fw = 0\n",
    "    #             for prev in transition[trans]:\n",
    "    #                 if transition[prev][trans] != 0:\n",
    "    #                     fw += math.exp(forward[prev][-1] + math.log10(transition[prev][trans]))\n",
    "    #             fw = math.log10(fw) + math.log10(emission[trans][o])\n",
    "    #         forward[trans].append(fw)\n",
    "    forward = list(dict((key, 0) for key in transition.keys()) for i in range(len(seq)))\n",
    "    for ind, o in enumerate(seq):\n",
    "        for trans in transition:\n",
    "            fw = 0\n",
    "            if ind == 0:\n",
    "                if not(emission[trans][o] == 0 or state[trans] == 0):\n",
    "                    fw = emission[trans][o] * state[trans]\n",
    "            else:\n",
    "                for prev in transition[trans]:\n",
    "                    if transition[prev][trans] != 0:\n",
    "                        print(trans, prev, forward[ind-1][prev], transition[prev][trans], emission[trans][o])\n",
    "                        fw += forward[ind-1][prev] * transition[prev][trans] * emission[trans][o]\n",
    "            forward[ind][trans] = fw\n",
    "        # normalize\n",
    "        tot = sum(forward[ind].values())\n",
    "        for t in forward[ind]: \n",
    "            forward[ind][t] /= tot\n",
    "    return forward\n",
    "\n",
    "json_file = \"./tests/stoch_hmm.json\"\n",
    "seq = \"umbrella, umbrella, no_umbrella, umbrella, umbrella\"\n",
    "f = stochastic_viterbi(json_file, seq)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65fbd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rain': 0.8181818181818181, 'no_rain': 0.18181818181818182} {'rain': 0.8182, 'no_rain': 0.181}\n",
      "{'rain': 0.8181818181818181, 'no_rain': 0.18181818181818182} {'rain': 0.8182, 'no_rain': 0.181}\n",
      "{'rain': 0.883357041251778, 'no_rain': 0.1166429587482219} {'rain': 0.8834, 'no_rain': 0.1166}\n",
      "{'rain': 0.883357041251778, 'no_rain': 0.1166429587482219} {'rain': 0.8834, 'no_rain': 0.1166}\n",
      "{'rain': 0.19066793972352525, 'no_rain': 0.8093320602764748} {'rain': 0.1907, 'no_rain': 0.8093}\n",
      "{'rain': 0.19066793972352525, 'no_rain': 0.8093320602764748} {'rain': 0.1907, 'no_rain': 0.8093}\n",
      "{'rain': 0.730794004584982, 'no_rain': 0.26920599541501794} {'rain': 0.7308, 'no_rain': 0.2692}\n",
      "{'rain': 0.730794004584982, 'no_rain': 0.26920599541501794} {'rain': 0.7308, 'no_rain': 0.2692}\n",
      "{'rain': 0.8673388895754847, 'no_rain': 0.13266111042451528} {'rain': 0.8673, 'no_rain': 0.1327}\n",
      "{'rain': 0.8673388895754847, 'no_rain': 0.13266111042451528} {'rain': 0.8673, 'no_rain': 0.1327}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seq = \"umbrella, umbrella, no_umbrella, umbrella, umbrella\"\n",
    "seq = seq.split(\", \")\n",
    "vals = [0.8182, 0.181, 0.8834, 0.1166, 0.1907, 0.8093, 0.7308, 0.2692, 0.8673, 0.1327]\n",
    "correct = list(dict((key, vals[i*2+j]) for j, key in enumerate([\"rain\", \"no_rain\"])) for i in range(len(seq)))\n",
    "for i, j in zip(f, correct):\n",
    "    for k in i:\n",
    "        print(i, j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2297f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rain': 0.8182, 'no_rain': 0.181},\n",
       " {'rain': 0.8834, 'no_rain': 0.1166},\n",
       " {'rain': 0.1907, 'no_rain': 0.8093},\n",
       " {'rain': 0.7308, 'no_rain': 0.2692},\n",
       " {'rain': 0.8673, 'no_rain': 0.1327}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = [0.8182, 0.181, 0.8834, 0.1166, 0.1907, 0.8093, 0.7308, 0.2692, 0.8673, 0.1327]\n",
    "correct = list(dict((key, vals[i*2+j]) for j, key in enumerate([\"rain\", \"no_rain\"])) for i in range(len(seq)))\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68d3425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 no_rain 0.37272727272727274 0.12992794153576687\n",
      "3 no_rain 0.34665718349928876 0.20083855701772588\n",
      "2 no_rain 0.6237328241105898 0.1166429587482219\n",
      "1 no_rain 0.4076823981660072 0.18181818181818182\n",
      "0 no_rain 0.3530644441698061 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'rain': 0.6469355558301939, 'no_rain': 0.3530644441698061},\n",
       "  {'rain': 0.5923176018339928, 'no_rain': 0.4076823981660072},\n",
       "  {'rain': 0.37626717588941005, 'no_rain': 0.6237328241105898},\n",
       "  {'rain': 0.6533428165007112, 'no_rain': 0.34665718349928876},\n",
       "  {'rain': 0.6272727272727272, 'no_rain': 0.37272727272727274},\n",
       "  {'rain': 1, 'no_rain': 1}],\n",
       " [{'rain': 0.0, 'no_rain': 0.17653222208490305},\n",
       "  {'rain': 0, 'no_rain': 0.07412407239381949},\n",
       "  {'rain': 0, 'no_rain': 0.07275404207264348},\n",
       "  {'rain': 0, 'no_rain': 0.06962212851382617},\n",
       "  {'rain': 0, 'no_rain': 0.048427687299694926},\n",
       "  {'rain': 0, 'no_rain': 0}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Backward Probability ###\n",
    "seq = \"umbrella, umbrella, no_umbrella, umbrella, umbrella\"\n",
    "seq = seq.split(\", \")\n",
    "smoothed = list(dict((key, 0) for key in transition.keys()) for i in range(len(seq)))\n",
    "backward = list(dict((key, 0) for key in transition.keys()) for i in range(len(seq)))\n",
    "backward.append(dict((key, 1) for key in transition.keys()))\n",
    "smoothed.insert(0, dict((key, backward[0][key] * forward[0][key]) for key in transition.keys()))\n",
    "for o, ind in zip(seq[::-1], reversed(range(len(seq)))):\n",
    "    for trans in transition:\n",
    "        bw = 0\n",
    "        for next in transition[trans]:\n",
    "            if transition[next][trans] != 0:\n",
    "                # print(ind, o, trans, next, backward[ind+1][next], transition[trans][next], emission[next][o])\n",
    "                bw += backward[ind+1][next] * transition[next][trans] * emission[next][o]\n",
    "        backward[ind][trans] = bw\n",
    "    # normalize\n",
    "    tot = sum(backward[ind].values())\n",
    "    for t in backward[ind]:\n",
    "        backward[ind][t] /= tot\n",
    "backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3edb265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'no_rain': 0.6469, 'rain': 0.3531},\n",
       " {'no_rain': 0.5923, 'rain': 0.4077},\n",
       " {'no_rain': 0.3763, 'rain': 0.6237},\n",
       " {'no_rain': 0.6533, 'rain': 0.3467},\n",
       " {'no_rain': 0.6273, 'rain': 0.3727},\n",
       " {'no_rain': 1.0, 'rain': 1.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = [1.0, 1.0, 0.6273, 0.3727, 0.6533, 0.3467, 0.3763, 0.6237, 0.5923, 0.4077, 0.6469, 0.3531]\n",
    "correct = list(dict((key, vals[i*2+j]) for j, key in enumerate([\"no_rain\", \"rain\"])) for i in range(len(seq)+1))\n",
    "correct.reverse()\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67182916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rain': 0.32346777791509695, 'no_rain': 0.17653222208490305},\n",
       " {'rain': 0.4846234924096305, 'no_rain': 0.07412407239381949},\n",
       " {'rain': 0.33237825921383163, 'no_rain': 0.07275404207264348},\n",
       " {'rain': 0.5221263879968115, 'no_rain': 0.06962212851382617},\n",
       " {'rain': 0.5457724730366552, 'no_rain': 0.048427687299694926},\n",
       " {'rain': 0.9184993701915494, 'no_rain': 0.0815006298084507}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Smoothed Values ###\n",
    "smoothed = list(dict((key, 0) for key in transition.keys()) for i in range(len(seq)))\n",
    "smoothed.insert(0, dict((key, backward[0][key] * forward[0][key]) for key in transition.keys()))\n",
    "for ind in range(len(forward)):\n",
    "    for trans in transition.keys():\n",
    "        smoothed[ind][trans] = backward[ind][trans] * forward[ind][trans]\n",
    "    # normalize\n",
    "    tot = sum(backward[ind].values())\n",
    "    for t in backward[ind]:\n",
    "        backward[ind][t] /= tot\n",
    "smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047df2a",
   "metadata": {},
   "source": [
    "### Traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ddaf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'rain': 0.5, 'no_rain': 0.5},\n",
       "  {'rain': 0.8181818181818181, 'no_rain': 0.18181818181818182},\n",
       "  {'rain': 0.883357041251778, 'no_rain': 0.1166429587482219},\n",
       "  {'rain': 0.19066793972352525, 'no_rain': 0.8093320602764748},\n",
       "  {'rain': 0.730794004584982, 'no_rain': 0.26920599541501794},\n",
       "  {'rain': 0.8673388895754847, 'no_rain': 0.13266111042451528}],\n",
       " [{'rain': 0.6469355558301939, 'no_rain': 0.3530644441698061},\n",
       "  {'rain': 0.5923176018339928, 'no_rain': 0.4076823981660072},\n",
       "  {'rain': 0.37626717588941005, 'no_rain': 0.6237328241105898},\n",
       "  {'rain': 0.6533428165007112, 'no_rain': 0.34665718349928876},\n",
       "  {'rain': 0.6272727272727272, 'no_rain': 0.37272727272727274},\n",
       "  {'rain': 1, 'no_rain': 1}],\n",
       " [{'rain': 0.19881051652268797, 'no_rain': 0.10850064411920954},\n",
       "  {'rain': 0.22456823748297028, 'no_rain': 0.034348133248295144},\n",
       "  {'rain': 0.11389274375820754, 'no_rain': 0.024929902126428292},\n",
       "  {'rain': 0.07961253155910467, 'no_rain': 0.1793038391721608},\n",
       "  {'rain': 0.5042478631636376, 'no_rain': 0.11037445812015736},\n",
       "  {'rain': 0, 'no_rain': 0}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stochastic_viterbi as sv\n",
    "json_file = \"./tests/stoch_hmm.json\"\n",
    "seq = \"umbrella, umbrella, no_umbrella, umbrella, umbrella\"\n",
    "sv.stochastic_viterbi(json_file, seq, log=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fd4b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2645289944.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [11]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "traceback = 10\n",
    "for t in traceback:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5aca75de5b3d64f50dd0e2287a96b9573c5d5b631eb4f18b50715cea01f8faab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
